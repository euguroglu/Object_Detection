{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detecting Objects in Video with OpenCV deep learning library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm:\n",
    "Reading input video --> Loading YOLO v3 Network -->\n",
    "--> Reading frames in the loop --> Getting blob from the frame -->\n",
    "--> Implementing Forward Pass --> Getting Bounding Boxes -->\n",
    "--> Non-maximum Suppression --> Drawing Bounding Boxes with Labels -->\n",
    "--> Writing processed frames\n",
    "\n",
    "Result:\n",
    "New video file with Detected Objects, Bounding Boxes and Labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['conv_0', 'bn_0', 'relu_1', 'conv_1', 'bn_1', 'relu_2', 'conv_2', 'bn_2', 'relu_3', 'conv_3', 'bn_3', 'relu_4', 'shortcut_4', 'conv_5', 'bn_5', 'relu_6', 'conv_6', 'bn_6', 'relu_7', 'conv_7', 'bn_7', 'relu_8', 'shortcut_8', 'conv_9', 'bn_9', 'relu_10', 'conv_10', 'bn_10', 'relu_11', 'shortcut_11', 'conv_12', 'bn_12', 'relu_13', 'conv_13', 'bn_13', 'relu_14', 'conv_14', 'bn_14', 'relu_15', 'shortcut_15', 'conv_16', 'bn_16', 'relu_17', 'conv_17', 'bn_17', 'relu_18', 'shortcut_18', 'conv_19', 'bn_19', 'relu_20', 'conv_20', 'bn_20', 'relu_21', 'shortcut_21', 'conv_22', 'bn_22', 'relu_23', 'conv_23', 'bn_23', 'relu_24', 'shortcut_24', 'conv_25', 'bn_25', 'relu_26', 'conv_26', 'bn_26', 'relu_27', 'shortcut_27', 'conv_28', 'bn_28', 'relu_29', 'conv_29', 'bn_29', 'relu_30', 'shortcut_30', 'conv_31', 'bn_31', 'relu_32', 'conv_32', 'bn_32', 'relu_33', 'shortcut_33', 'conv_34', 'bn_34', 'relu_35', 'conv_35', 'bn_35', 'relu_36', 'shortcut_36', 'conv_37', 'bn_37', 'relu_38', 'conv_38', 'bn_38', 'relu_39', 'conv_39', 'bn_39', 'relu_40', 'shortcut_40', 'conv_41', 'bn_41', 'relu_42', 'conv_42', 'bn_42', 'relu_43', 'shortcut_43', 'conv_44', 'bn_44', 'relu_45', 'conv_45', 'bn_45', 'relu_46', 'shortcut_46', 'conv_47', 'bn_47', 'relu_48', 'conv_48', 'bn_48', 'relu_49', 'shortcut_49', 'conv_50', 'bn_50', 'relu_51', 'conv_51', 'bn_51', 'relu_52', 'shortcut_52', 'conv_53', 'bn_53', 'relu_54', 'conv_54', 'bn_54', 'relu_55', 'shortcut_55', 'conv_56', 'bn_56', 'relu_57', 'conv_57', 'bn_57', 'relu_58', 'shortcut_58', 'conv_59', 'bn_59', 'relu_60', 'conv_60', 'bn_60', 'relu_61', 'shortcut_61', 'conv_62', 'bn_62', 'relu_63', 'conv_63', 'bn_63', 'relu_64', 'conv_64', 'bn_64', 'relu_65', 'shortcut_65', 'conv_66', 'bn_66', 'relu_67', 'conv_67', 'bn_67', 'relu_68', 'shortcut_68', 'conv_69', 'bn_69', 'relu_70', 'conv_70', 'bn_70', 'relu_71', 'shortcut_71', 'conv_72', 'bn_72', 'relu_73', 'conv_73', 'bn_73', 'relu_74', 'shortcut_74', 'conv_75', 'bn_75', 'relu_76', 'conv_76', 'bn_76', 'relu_77', 'conv_77', 'bn_77', 'relu_78', 'conv_78', 'bn_78', 'relu_79', 'conv_79', 'bn_79', 'relu_80', 'conv_80', 'bn_80', 'relu_81', 'conv_81', 'permute_82', 'yolo_82', 'identity_83', 'conv_84', 'bn_84', 'relu_85', 'upsample_85', 'concat_86', 'conv_87', 'bn_87', 'relu_88', 'conv_88', 'bn_88', 'relu_89', 'conv_89', 'bn_89', 'relu_90', 'conv_90', 'bn_90', 'relu_91', 'conv_91', 'bn_91', 'relu_92', 'conv_92', 'bn_92', 'relu_93', 'conv_93', 'permute_94', 'yolo_94', 'identity_95', 'conv_96', 'bn_96', 'relu_97', 'upsample_97', 'concat_98', 'conv_99', 'bn_99', 'relu_100', 'conv_100', 'bn_100', 'relu_101', 'conv_101', 'bn_101', 'relu_102', 'conv_102', 'bn_102', 'relu_103', 'conv_103', 'bn_103', 'relu_104', 'conv_104', 'bn_104', 'relu_105', 'conv_105', 'permute_106', 'yolo_106']\n",
      "\n",
      "['yolo_82', 'yolo_94', 'yolo_106']\n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "(80, 3)\n",
      "[108 117 168]\n",
      "Frame number 1 took 0.75382 seconds\n",
      "Frame number 2 took 0.44677 seconds\n",
      "Frame number 3 took 0.41787 seconds\n",
      "Frame number 4 took 0.38696 seconds\n",
      "Frame number 5 took 0.38896 seconds\n",
      "Frame number 6 took 0.38497 seconds\n",
      "Frame number 7 took 0.38497 seconds\n",
      "Frame number 8 took 0.38996 seconds\n",
      "Frame number 9 took 0.38593 seconds\n",
      "Frame number 10 took 0.40691 seconds\n",
      "Frame number 11 took 0.39993 seconds\n",
      "Frame number 12 took 0.38297 seconds\n",
      "Frame number 13 took 0.38294 seconds\n",
      "Frame number 14 took 0.38995 seconds\n",
      "Frame number 15 took 0.38095 seconds\n",
      "Frame number 16 took 0.38696 seconds\n",
      "Frame number 17 took 0.38594 seconds\n",
      "Frame number 18 took 0.39095 seconds\n",
      "Frame number 19 took 0.39096 seconds\n",
      "Frame number 20 took 0.40592 seconds\n",
      "Frame number 21 took 0.38597 seconds\n",
      "Frame number 22 took 0.41485 seconds\n",
      "Frame number 23 took 0.38694 seconds\n",
      "Frame number 24 took 0.43583 seconds\n",
      "Frame number 25 took 0.38297 seconds\n",
      "Frame number 26 took 0.43979 seconds\n",
      "Frame number 27 took 0.47969 seconds\n",
      "Frame number 28 took 0.46073 seconds\n",
      "Frame number 29 took 0.38696 seconds\n",
      "Frame number 30 took 0.38494 seconds\n",
      "Frame number 31 took 0.37898 seconds\n",
      "Frame number 32 took 0.38195 seconds\n",
      "Frame number 33 took 0.39793 seconds\n",
      "Frame number 34 took 0.38297 seconds\n",
      "Frame number 35 took 0.38597 seconds\n",
      "Frame number 36 took 0.38095 seconds\n",
      "Frame number 37 took 0.38494 seconds\n",
      "Frame number 38 took 0.37998 seconds\n",
      "Frame number 39 took 0.38098 seconds\n",
      "Frame number 40 took 0.37896 seconds\n",
      "Frame number 41 took 0.38194 seconds\n",
      "Frame number 42 took 0.37500 seconds\n",
      "Frame number 43 took 0.39295 seconds\n",
      "Frame number 44 took 0.37699 seconds\n",
      "Frame number 45 took 0.38198 seconds\n",
      "Frame number 46 took 0.37799 seconds\n",
      "Frame number 47 took 0.37898 seconds\n",
      "Frame number 48 took 0.38499 seconds\n",
      "Frame number 49 took 0.38295 seconds\n",
      "Frame number 50 took 0.37796 seconds\n",
      "Frame number 51 took 0.39594 seconds\n",
      "Frame number 52 took 0.37600 seconds\n",
      "Frame number 53 took 0.37898 seconds\n",
      "Frame number 54 took 0.37796 seconds\n",
      "Frame number 55 took 0.38394 seconds\n",
      "Frame number 56 took 0.37699 seconds\n",
      "Frame number 57 took 0.38294 seconds\n",
      "Frame number 58 took 0.37696 seconds\n",
      "Frame number 59 took 0.37995 seconds\n",
      "Frame number 60 took 0.37696 seconds\n",
      "Frame number 61 took 0.37898 seconds\n",
      "Frame number 62 took 0.44578 seconds\n",
      "Frame number 63 took 0.46875 seconds\n",
      "Frame number 64 took 0.43084 seconds\n",
      "Frame number 65 took 0.43185 seconds\n",
      "Frame number 66 took 0.38697 seconds\n",
      "Frame number 67 took 0.38297 seconds\n",
      "Frame number 68 took 0.40193 seconds\n",
      "Frame number 69 took 0.37799 seconds\n",
      "Frame number 70 took 0.37500 seconds\n",
      "Frame number 71 took 0.37699 seconds\n",
      "Frame number 72 took 0.37400 seconds\n",
      "Frame number 73 took 0.38095 seconds\n",
      "Frame number 74 took 0.37200 seconds\n",
      "Frame number 75 took 0.38397 seconds\n",
      "Frame number 76 took 0.37799 seconds\n",
      "Frame number 77 took 0.38095 seconds\n",
      "Frame number 78 took 0.37400 seconds\n",
      "Frame number 79 took 0.37396 seconds\n",
      "Frame number 80 took 0.37799 seconds\n",
      "Frame number 81 took 0.37297 seconds\n",
      "Frame number 82 took 0.38497 seconds\n",
      "Frame number 83 took 0.37696 seconds\n",
      "Frame number 84 took 0.37500 seconds\n",
      "Frame number 85 took 0.37300 seconds\n",
      "Frame number 86 took 0.37599 seconds\n",
      "Frame number 87 took 0.39192 seconds\n",
      "Frame number 88 took 0.38095 seconds\n",
      "Frame number 89 took 0.37799 seconds\n",
      "Frame number 90 took 0.37596 seconds\n",
      "Frame number 91 took 0.37899 seconds\n",
      "Frame number 92 took 0.37699 seconds\n",
      "Frame number 93 took 0.37499 seconds\n",
      "Frame number 94 took 0.37697 seconds\n",
      "Frame number 95 took 0.37497 seconds\n",
      "Frame number 96 took 0.37699 seconds\n",
      "Frame number 97 took 0.39691 seconds\n",
      "Frame number 98 took 0.48268 seconds\n",
      "Frame number 99 took 0.45179 seconds\n",
      "Frame number 100 took 0.41289 seconds\n",
      "Frame number 101 took 0.38198 seconds\n",
      "Frame number 102 took 0.37899 seconds\n",
      "Frame number 103 took 0.37496 seconds\n",
      "Frame number 104 took 0.37599 seconds\n",
      "Frame number 105 took 0.37799 seconds\n",
      "Frame number 106 took 0.37300 seconds\n",
      "Frame number 107 took 0.37600 seconds\n",
      "Frame number 108 took 0.37499 seconds\n",
      "Frame number 109 took 0.37596 seconds\n",
      "Frame number 110 took 0.37200 seconds\n",
      "Frame number 111 took 0.37496 seconds\n",
      "Frame number 112 took 0.37696 seconds\n",
      "Frame number 113 took 0.37396 seconds\n",
      "Frame number 114 took 0.38198 seconds\n",
      "Frame number 115 took 0.37498 seconds\n",
      "Frame number 116 took 0.38297 seconds\n",
      "Frame number 117 took 0.37896 seconds\n",
      "Frame number 118 took 0.37499 seconds\n",
      "Frame number 119 took 0.37599 seconds\n",
      "Frame number 120 took 0.37799 seconds\n",
      "Frame number 121 took 0.37998 seconds\n",
      "Frame number 122 took 0.37397 seconds\n",
      "Frame number 123 took 0.39295 seconds\n",
      "Frame number 124 took 0.38497 seconds\n",
      "Frame number 125 took 0.37699 seconds\n",
      "Frame number 126 took 0.37899 seconds\n",
      "Frame number 127 took 0.37898 seconds\n",
      "Frame number 128 took 0.40292 seconds\n",
      "Frame number 129 took 0.37696 seconds\n",
      "Frame number 130 took 0.38397 seconds\n",
      "Frame number 131 took 0.37496 seconds\n",
      "Frame number 132 took 0.37699 seconds\n",
      "Frame number 133 took 0.41788 seconds\n",
      "Frame number 134 took 0.47872 seconds\n",
      "Frame number 135 took 0.45378 seconds\n",
      "Frame number 136 took 0.40691 seconds\n",
      "Frame number 137 took 0.39793 seconds\n",
      "Frame number 138 took 0.37500 seconds\n",
      "Frame number 139 took 0.37799 seconds\n",
      "Frame number 140 took 0.37696 seconds\n",
      "Frame number 141 took 0.37997 seconds\n",
      "Frame number 142 took 0.37898 seconds\n",
      "Frame number 143 took 0.37699 seconds\n",
      "Frame number 144 took 0.37599 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame number 145 took 0.38094 seconds\n",
      "Frame number 146 took 0.37500 seconds\n",
      "Frame number 147 took 0.38096 seconds\n",
      "Frame number 148 took 0.37799 seconds\n",
      "Frame number 149 took 0.37696 seconds\n",
      "Frame number 150 took 0.37896 seconds\n",
      "Frame number 151 took 0.37500 seconds\n",
      "Frame number 152 took 0.37297 seconds\n",
      "Frame number 153 took 0.37699 seconds\n",
      "Frame number 154 took 0.37599 seconds\n",
      "Frame number 155 took 0.37599 seconds\n",
      "Frame number 156 took 0.37300 seconds\n",
      "Frame number 157 took 0.37698 seconds\n",
      "Frame number 158 took 0.37596 seconds\n",
      "Frame number 159 took 0.37500 seconds\n",
      "Frame number 160 took 0.39095 seconds\n",
      "Frame number 161 took 0.37696 seconds\n",
      "Frame number 162 took 0.38394 seconds\n",
      "Frame number 163 took 0.37799 seconds\n",
      "Frame number 164 took 0.37499 seconds\n",
      "Frame number 165 took 0.37899 seconds\n",
      "Frame number 166 took 0.37699 seconds\n",
      "Frame number 167 took 0.37596 seconds\n",
      "Frame number 168 took 0.37500 seconds\n",
      "Frame number 169 took 0.44179 seconds\n",
      "Frame number 170 took 0.45278 seconds\n",
      "Frame number 171 took 0.44877 seconds\n",
      "Frame number 172 took 0.40894 seconds\n",
      "Frame number 173 took 0.40491 seconds\n",
      "Frame number 174 took 0.37799 seconds\n",
      "Frame number 175 took 0.37699 seconds\n",
      "Frame number 176 took 0.37699 seconds\n",
      "Frame number 177 took 0.37699 seconds\n",
      "Frame number 178 took 0.37397 seconds\n",
      "Frame number 179 took 0.37799 seconds\n",
      "Frame number 180 took 0.37799 seconds\n",
      "Frame number 181 took 0.40492 seconds\n",
      "Frame number 182 took 0.42085 seconds\n",
      "Frame number 183 took 0.43483 seconds\n",
      "Frame number 184 took 0.42686 seconds\n",
      "Frame number 185 took 0.41289 seconds\n",
      "Frame number 186 took 0.38195 seconds\n",
      "Frame number 187 took 0.39893 seconds\n",
      "Frame number 188 took 0.39392 seconds\n",
      "Frame number 189 took 0.39195 seconds\n",
      "Frame number 190 took 0.42486 seconds\n",
      "Frame number 191 took 0.39893 seconds\n",
      "Frame number 192 took 0.43683 seconds\n",
      "Frame number 193 took 0.42985 seconds\n",
      "Frame number 194 took 0.41689 seconds\n",
      "Frame number 195 took 0.43284 seconds\n",
      "Frame number 196 took 0.41290 seconds\n",
      "Frame number 197 took 0.41489 seconds\n",
      "Frame number 198 took 0.43384 seconds\n",
      "Frame number 199 took 0.44578 seconds\n",
      "Frame number 200 took 0.41789 seconds\n",
      "Frame number 201 took 0.40890 seconds\n",
      "Frame number 202 took 0.46974 seconds\n",
      "Frame number 203 took 0.47869 seconds\n",
      "Frame number 204 took 0.51562 seconds\n",
      "Frame number 205 took 0.45777 seconds\n",
      "Frame number 206 took 0.75997 seconds\n",
      "Frame number 207 took 0.52759 seconds\n",
      "Frame number 208 took 0.52859 seconds\n",
      "Frame number 209 took 0.51762 seconds\n",
      "Frame number 210 took 0.47274 seconds\n",
      "Frame number 211 took 0.50864 seconds\n",
      "Frame number 212 took 0.63829 seconds\n",
      "Frame number 213 took 0.47473 seconds\n",
      "Frame number 214 took 0.45578 seconds\n",
      "Frame number 215 took 0.42790 seconds\n",
      "Frame number 216 took 0.41343 seconds\n",
      "Frame number 217 took 0.40990 seconds\n",
      "Frame number 218 took 0.40558 seconds\n",
      "Frame number 219 took 0.40489 seconds\n",
      "Frame number 220 took 0.40844 seconds\n",
      "Frame number 221 took 0.42683 seconds\n",
      "Frame number 222 took 0.39993 seconds\n",
      "Frame number 223 took 0.39747 seconds\n",
      "Frame number 224 took 0.39397 seconds\n",
      "Frame number 225 took 0.41486 seconds\n",
      "Frame number 226 took 0.40093 seconds\n",
      "Frame number 227 took 0.39453 seconds\n",
      "Frame number 228 took 0.39677 seconds\n",
      "Frame number 229 took 0.39394 seconds\n",
      "Frame number 230 took 0.40443 seconds\n",
      "Frame number 231 took 0.39844 seconds\n",
      "Frame number 232 took 0.40394 seconds\n",
      "Frame number 233 took 0.43484 seconds\n",
      "Frame number 234 took 0.50217 seconds\n",
      "Frame number 235 took 0.50966 seconds\n",
      "Frame number 236 took 0.50066 seconds\n",
      "Frame number 237 took 0.43136 seconds\n",
      "Frame number 238 took 0.43951 seconds\n",
      "Frame number 239 took 0.41589 seconds\n",
      "Frame number 240 took 0.39994 seconds\n",
      "Frame number 241 took 0.38698 seconds\n",
      "Frame number 242 took 0.39681 seconds\n",
      "Frame number 243 took 0.42366 seconds\n",
      "Frame number 244 took 0.42965 seconds\n",
      "Frame number 245 took 0.40715 seconds\n",
      "Frame number 246 took 0.40443 seconds\n",
      "Frame number 247 took 0.39694 seconds\n",
      "Frame number 248 took 0.47376 seconds\n",
      "Frame number 249 took 0.40940 seconds\n",
      "Frame number 250 took 0.49467 seconds\n",
      "Frame number 251 took 0.43684 seconds\n",
      "Frame number 252 took 0.55503 seconds\n",
      "Frame number 253 took 0.47573 seconds\n",
      "Frame number 254 took 0.44782 seconds\n",
      "Frame number 255 took 0.43384 seconds\n",
      "Frame number 256 took 0.43979 seconds\n",
      "Frame number 257 took 0.45079 seconds\n",
      "Frame number 258 took 0.47973 seconds\n",
      "Frame number 259 took 0.54705 seconds\n",
      "Frame number 260 took 0.47573 seconds\n",
      "Frame number 261 took 0.47924 seconds\n",
      "Frame number 262 took 0.42438 seconds\n",
      "Frame number 263 took 0.43282 seconds\n",
      "Frame number 264 took 0.50764 seconds\n",
      "Frame number 265 took 0.56511 seconds\n",
      "Frame number 266 took 0.51066 seconds\n",
      "Frame number 267 took 0.52264 seconds\n",
      "Frame number 268 took 0.50616 seconds\n",
      "Frame number 269 took 0.46135 seconds\n",
      "Frame number 270 took 0.48670 seconds\n",
      "Frame number 271 took 0.47548 seconds\n",
      "Frame number 272 took 0.42990 seconds\n",
      "Frame number 273 took 0.49069 seconds\n",
      "Frame number 274 took 0.48422 seconds\n",
      "Frame number 275 took 0.47309 seconds\n",
      "Frame number 276 took 0.48168 seconds\n",
      "Frame number 277 took 0.47074 seconds\n",
      "Frame number 278 took 0.45433 seconds\n",
      "Frame number 279 took 0.46476 seconds\n",
      "Frame number 280 took 0.47974 seconds\n",
      "Frame number 281 took 0.51014 seconds\n",
      "Frame number 282 took 0.46378 seconds\n",
      "Frame number 283 took 0.47573 seconds\n",
      "Frame number 284 took 0.45758 seconds\n",
      "Frame number 285 took 0.43486 seconds\n",
      "Frame number 286 took 0.42187 seconds\n",
      "Frame number 287 took 0.42785 seconds\n",
      "Frame number 288 took 0.45282 seconds\n",
      "Frame number 289 took 0.45079 seconds\n",
      "Frame number 290 took 0.46436 seconds\n",
      "Frame number 291 took 0.45284 seconds\n",
      "Frame number 292 took 0.46130 seconds\n",
      "Frame number 293 took 0.45675 seconds\n",
      "Frame number 294 took 0.53510 seconds\n",
      "Frame number 295 took 0.56996 seconds\n",
      "Frame number 296 took 0.46427 seconds\n",
      "Frame number 297 took 0.49454 seconds\n",
      "Frame number 298 took 0.46923 seconds\n",
      "Frame number 299 took 0.48023 seconds\n",
      "Frame number 300 took 0.49268 seconds\n",
      "Frame number 301 took 0.43281 seconds\n",
      "Frame number 302 took 0.44282 seconds\n",
      "Frame number 303 took 0.47801 seconds\n",
      "Frame number 304 took 0.44801 seconds\n",
      "Frame number 305 took 0.45079 seconds\n",
      "Frame number 306 took 0.45052 seconds\n",
      "Frame number 307 took 0.46558 seconds\n",
      "Frame number 308 took 0.49168 seconds\n",
      "Frame number 309 took 0.46376 seconds\n",
      "Frame number 310 took 0.47575 seconds\n",
      "Frame number 311 took 0.46473 seconds\n",
      "Frame number 312 took 0.43934 seconds\n",
      "Frame number 313 took 0.44187 seconds\n",
      "Frame number 314 took 0.43883 seconds\n",
      "Frame number 315 took 0.46527 seconds\n",
      "Frame number 316 took 0.45941 seconds\n",
      "Frame number 317 took 0.44381 seconds\n",
      "Frame number 318 took 0.44683 seconds\n",
      "Frame number 319 took 0.43887 seconds\n",
      "Frame number 320 took 0.41292 seconds\n",
      "Frame number 321 took 0.41785 seconds\n",
      "Frame number 322 took 0.43683 seconds\n",
      "Frame number 323 took 0.47724 seconds\n",
      "Frame number 324 took 0.55252 seconds\n",
      "Frame number 325 took 0.49419 seconds\n",
      "Frame number 326 took 0.48322 seconds\n",
      "Frame number 327 took 0.51861 seconds\n",
      "Frame number 328 took 0.44780 seconds\n",
      "Frame number 329 took 0.45778 seconds\n",
      "Frame number 330 took 0.45580 seconds\n",
      "Frame number 331 took 0.42540 seconds\n",
      "Frame number 332 took 0.41187 seconds\n",
      "Frame number 333 took 0.43834 seconds\n",
      "Frame number 334 took 0.43931 seconds\n",
      "Frame number 335 took 0.42686 seconds\n",
      "\n",
      "Total number of frames 335\n",
      "Total amount of time 140.68732 seconds\n",
      "FPS: 2.4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nSome comments\\n\\nWhat is a FOURCC?\\n    FOURCC is short for \"four character code\" - an identifier for a video codec,\\n    compression format, colour or pixel format used in media files.\\n    http://www.fourcc.org\\n\\n\\nParameters for cv2.VideoWriter():\\n    filename - Name of the output video file.\\n    fourcc - 4-character code of codec used to compress the frames.\\n    fps\\t- Frame rate of the created video.\\n    frameSize - Size of the video frames.\\n    isColor\\t- If it True, the encoder will expect and encode colour frames.\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Start of:\n",
    "Reading input video\n",
    "\"\"\"\n",
    "\n",
    "# Defining 'VideoCapture' object\n",
    "# and reading video from a file\n",
    "# Pay attention! If you're using Windows, the path might looks like:\n",
    "# r'videos\\traffic-cars.mp4'\n",
    "# or:\n",
    "# 'videos\\\\traffic-cars.mp4'\n",
    "video = cv2.VideoCapture('videos/traffic-cars.mp4')\n",
    "\n",
    "# Preparing variable for writer\n",
    "# that we will use to write processed frames\n",
    "writer = None\n",
    "\n",
    "# Preparing variables for spatial dimensions of the frames\n",
    "h, w = None, None\n",
    "\n",
    "\"\"\"\n",
    "End of:\n",
    "Reading input video\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Start of:\n",
    "Loading YOLO v3 network\n",
    "\"\"\"\n",
    "\n",
    "# Loading COCO class labels from file\n",
    "# Opening file\n",
    "# Pay attention! If you're using Windows, yours path might looks like:\n",
    "# r'yolo-coco-data\\coco.names'\n",
    "# or:\n",
    "# 'yolo-coco-data\\\\coco.names'\n",
    "with open('yolo-coco-data/coco.names') as f:\n",
    "    # Getting labels reading every line\n",
    "    # and putting them into the list\n",
    "    labels = [line.strip() for line in f]\n",
    "\n",
    "\n",
    "# # Check point\n",
    "# print('List with labels names:')\n",
    "# print(labels)\n",
    "\n",
    "# Loading trained YOLO v3 Objects Detector\n",
    "# with the help of 'dnn' library from OpenCV\n",
    "# Pay attention! If you're using Windows, yours paths might look like:\n",
    "# r'yolo-coco-data\\yolov3.cfg'\n",
    "# r'yolo-coco-data\\yolov3.weights'\n",
    "# or:\n",
    "# 'yolo-coco-data\\\\yolov3.cfg'\n",
    "# 'yolo-coco-data\\\\yolov3.weights'\n",
    "network = cv2.dnn.readNetFromDarknet('yolo-coco-data/yolov3.cfg',\n",
    "                                     'yolo-coco-data/yolov3.weights')\n",
    "\n",
    "# Getting list with names of all layers from YOLO v3 network\n",
    "layers_names_all = network.getLayerNames()\n",
    "\n",
    "# Check point\n",
    "print()\n",
    "print(layers_names_all)\n",
    "\n",
    "# Getting only output layers' names that we need from YOLO v3 algorithm\n",
    "# with function that returns indexes of layers with unconnected outputs\n",
    "layers_names_output = [layers_names_all[i[0] - 1] for i in network.getUnconnectedOutLayers()]\n",
    "\n",
    "# Check point\n",
    "print()\n",
    "print(layers_names_output)  # ['yolo_82', 'yolo_94', 'yolo_106']\n",
    "\n",
    "# Setting minimum probability to eliminate weak predictions\n",
    "probability_minimum = 0.5\n",
    "\n",
    "# Setting threshold for filtering weak bounding boxes\n",
    "# with non-maximum suppression\n",
    "threshold = 0.3\n",
    "\n",
    "# Generating colours for representing every detected object\n",
    "# with function randint(low, high=None, size=None, dtype='l')\n",
    "colours = np.random.randint(0, 255, size=(len(labels), 3), dtype='uint8')\n",
    "\n",
    "# Check point\n",
    "print()\n",
    "print(type(colours))  # <class 'numpy.ndarray'>\n",
    "print(colours.shape)  # (80, 3)\n",
    "print(colours[0])  # [172  10 127]\n",
    "\n",
    "\"\"\"\n",
    "End of:\n",
    "Loading YOLO v3 network\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Start of:\n",
    "Reading frames in the loop\n",
    "\"\"\"\n",
    "\n",
    "# Defining variable for counting frames\n",
    "# At the end we will show total amount of processed frames\n",
    "f = 0\n",
    "\n",
    "# Defining variable for counting total time\n",
    "# At the end we will show time spent for processing all frames\n",
    "t = 0\n",
    "\n",
    "# Defining loop for catching frames\n",
    "while True:\n",
    "    # Capturing frame-by-frame\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    # If the frame was not retrieved\n",
    "    # e.g.: at the end of the video,\n",
    "    # then we break the loop\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Getting spatial dimensions of the frame\n",
    "    # we do it only once from the very beginning\n",
    "    # all other frames have the same dimension\n",
    "    if w is None or h is None:\n",
    "        # Slicing from tuple only first two elements\n",
    "        h, w = frame.shape[:2]\n",
    "\n",
    "    \"\"\"\n",
    "    Start of:\n",
    "    Getting blob from current frame\n",
    "    \"\"\"\n",
    "\n",
    "    # Getting blob from current frame\n",
    "    # The 'cv2.dnn.blobFromImage' function returns 4-dimensional blob from current\n",
    "    # frame after mean subtraction, normalizing, and RB channels swapping\n",
    "    # Resulted shape has number of frames, number of channels, width and height\n",
    "    # E.G.:\n",
    "    # blob = cv2.dnn.blobFromImage(image, scalefactor=1.0, size, mean, swapRB=True)\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416),\n",
    "                                 swapRB=True, crop=False)\n",
    "\n",
    "    \"\"\"\n",
    "    End of:\n",
    "    Getting blob from current frame\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    Start of:\n",
    "    Implementing Forward pass\n",
    "    \"\"\"\n",
    "\n",
    "    # Implementing forward pass with our blob and only through output layers\n",
    "    # Calculating at the same time, needed time for forward pass\n",
    "    network.setInput(blob)  # setting blob as input to the network\n",
    "    start = time.time()\n",
    "    output_from_network = network.forward(layers_names_output)\n",
    "    end = time.time()\n",
    "\n",
    "    # Increasing counters for frames and total time\n",
    "    f += 1\n",
    "    t += end - start\n",
    "\n",
    "    # Showing spent time for single current frame\n",
    "    print('Frame number {0} took {1:.5f} seconds'.format(f, end - start))\n",
    "\n",
    "    \"\"\"\n",
    "    End of:\n",
    "    Implementing Forward pass\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    Start of:\n",
    "    Getting bounding boxes\n",
    "    \"\"\"\n",
    "\n",
    "    # Preparing lists for detected bounding boxes,\n",
    "    # obtained confidences and class's number\n",
    "    bounding_boxes = []\n",
    "    confidences = []\n",
    "    class_numbers = []\n",
    "\n",
    "    # Going through all output layers after feed forward pass\n",
    "    for result in output_from_network:\n",
    "        # Going through all detections from current output layer\n",
    "        for detected_objects in result:\n",
    "            # Getting 80 classes' probabilities for current detected object\n",
    "            scores = detected_objects[5:]\n",
    "            # Getting index of the class with the maximum value of probability\n",
    "            class_current = np.argmax(scores)\n",
    "            # Getting value of probability for defined class\n",
    "            confidence_current = scores[class_current]\n",
    "\n",
    "            # # Check point\n",
    "            # # Every 'detected_objects' numpy array has first 4 numbers with\n",
    "            # # bounding box coordinates and rest 80 with probabilities\n",
    "            #  # for every class\n",
    "            # print(detected_objects.shape)  # (85,)\n",
    "\n",
    "            # Eliminating weak predictions with minimum probability\n",
    "            if confidence_current > probability_minimum:\n",
    "                # Scaling bounding box coordinates to the initial frame size\n",
    "                # YOLO data format keeps coordinates for center of bounding box\n",
    "                # and its current width and height\n",
    "                # That is why we can just multiply them elementwise\n",
    "                # to the width and height\n",
    "                # of the original frame and in this way get coordinates for center\n",
    "                # of bounding box, its width and height for original frame\n",
    "                box_current = detected_objects[0:4] * np.array([w, h, w, h])\n",
    "\n",
    "                # Now, from YOLO data format, we can get top left corner coordinates\n",
    "                # that are x_min and y_min\n",
    "                x_center, y_center, box_width, box_height = box_current\n",
    "                x_min = int(x_center - (box_width / 2))\n",
    "                y_min = int(y_center - (box_height / 2))\n",
    "\n",
    "                # Adding results into prepared lists\n",
    "                bounding_boxes.append([x_min, y_min,\n",
    "                                       int(box_width), int(box_height)])\n",
    "                confidences.append(float(confidence_current))\n",
    "                class_numbers.append(class_current)\n",
    "\n",
    "    \"\"\"\n",
    "    End of:\n",
    "    Getting bounding boxes\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Start of:\n",
    "    Non-maximum suppression\n",
    "    \"\"\"\n",
    "\n",
    "    # Implementing non-maximum suppression of given bounding boxes\n",
    "    # With this technique we exclude some of bounding boxes if their\n",
    "    # corresponding confidences are low or there is another\n",
    "    # bounding box for this region with higher confidence\n",
    "\n",
    "    # It is needed to make sure that data type of the boxes is 'int'\n",
    "    # and data type of the confidences is 'float'\n",
    "    # https://github.com/opencv/opencv/issues/12789\n",
    "    results = cv2.dnn.NMSBoxes(bounding_boxes, confidences,\n",
    "                               probability_minimum, threshold)\n",
    "\n",
    "    \"\"\"\n",
    "    End of:\n",
    "    Non-maximum suppression\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    Start of:\n",
    "    Drawing bounding boxes and labels\n",
    "    \"\"\"\n",
    "\n",
    "    # Checking if there is at least one detected object\n",
    "    # after non-maximum suppression\n",
    "    if len(results) > 0:\n",
    "        # Going through indexes of results\n",
    "        for i in results.flatten():\n",
    "            # Getting current bounding box coordinates,\n",
    "            # its width and height\n",
    "            x_min, y_min = bounding_boxes[i][0], bounding_boxes[i][1]\n",
    "            box_width, box_height = bounding_boxes[i][2], bounding_boxes[i][3]\n",
    "\n",
    "            # Preparing colour for current bounding box\n",
    "            # and converting from numpy array to list\n",
    "            colour_box_current = colours[class_numbers[i]].tolist()\n",
    "\n",
    "            # # # Check point\n",
    "            # print(type(colour_box_current))  # <class 'list'>\n",
    "            # print(colour_box_current)  # [172 , 10, 127]\n",
    "\n",
    "            # Drawing bounding box on the original current frame\n",
    "            cv2.rectangle(frame, (x_min, y_min),\n",
    "                          (x_min + box_width, y_min + box_height),\n",
    "                          colour_box_current, 2)\n",
    "\n",
    "            # Preparing text with label and confidence for current bounding box\n",
    "            text_box_current = '{}: {:.4f}'.format(labels[int(class_numbers[i])],\n",
    "                                                   confidences[i])\n",
    "\n",
    "            # Putting text with label and confidence on the original image\n",
    "            cv2.putText(frame, text_box_current, (x_min, y_min - 5),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, colour_box_current, 2)\n",
    "\n",
    "    \"\"\"\n",
    "    End of:\n",
    "    Drawing bounding boxes and labels\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    Start of:\n",
    "    Writing processed frame into the file\n",
    "    \"\"\"\n",
    "\n",
    "    # Initializing writer\n",
    "    # we do it only once from the very beginning\n",
    "    # when we get spatial dimensions of the frames\n",
    "    if writer is None:\n",
    "        # Constructing code of the codec\n",
    "        # to be used in the function VideoWriter\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "        # Writing current processed frame into the video file\n",
    "        # Pay attention! If you're using Windows, yours path might looks like:\n",
    "        # r'videos\\result-traffic-cars.mp4'\n",
    "        # or:\n",
    "        # 'videos\\\\result-traffic-cars.mp4'\n",
    "        writer = cv2.VideoWriter('videos/result-traffic-cars.mp4', fourcc, 30,\n",
    "                                 (frame.shape[1], frame.shape[0]), True)\n",
    "\n",
    "    # Write processed current frame to the file\n",
    "    writer.write(frame)\n",
    "\n",
    "    \"\"\"\n",
    "    End of:\n",
    "    Writing processed frame into the file\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "\n",
    "# Printing final results\n",
    "print()\n",
    "print('Total number of frames', f)\n",
    "print('Total amount of time {:.5f} seconds'.format(t))\n",
    "print('FPS:', round((f / t), 1))\n",
    "\n",
    "\n",
    "# Releasing video reader and writer\n",
    "video.release()\n",
    "writer.release()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Some comments\n",
    "\n",
    "What is a FOURCC?\n",
    "    FOURCC is short for \"four character code\" - an identifier for a video codec,\n",
    "    compression format, colour or pixel format used in media files.\n",
    "    http://www.fourcc.org\n",
    "\n",
    "\n",
    "Parameters for cv2.VideoWriter():\n",
    "    filename - Name of the output video file.\n",
    "    fourcc - 4-character code of codec used to compress the frames.\n",
    "    fps\t- Frame rate of the created video.\n",
    "    frameSize - Size of the video frames.\n",
    "    isColor\t- If it True, the encoder will expect and encode colour frames.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
